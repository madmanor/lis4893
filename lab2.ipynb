{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAQUaXM245PLduZI40OFo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madmanor/lis4893/blob/main/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Fz826m6BZtA8",
        "outputId": "25a339a5-2e41-4785-cbbf-bd1ae7391433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.24.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.3)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (0.24.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.1)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "BUOF89T1bQw6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/madmanor/lis4893/refs/heads/main/transcript.txt\"\n",
        "response = requests.get(url)\n",
        "response.raise_for_status() # Raise an exception for HTTP errors\n",
        "text = response.text"
      ],
      "metadata": {
        "id": "RHyfORghgvZl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of characters:\", len(text)) # print number of characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GecJt_BXhkxh",
        "outputId": "fc853991-ad8e-45e8-bfa8-176bd6f6b8e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of characters: 3577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 192236 characters"
      ],
      "metadata": {
        "id": "81kA6URSh0pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:300])   # print first 300 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jwD07Aeh4He",
        "outputId": "6f79b157-1ca7-46a8-9c1b-029484f69b2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all right now this is a trial by combat\n",
            "if I am correct between sir Duncan the\n",
            "tall of the Kingsguard and Lord\n",
            "lyonel Baratheon and this is the the\n",
            "character in white sir Duncan is the\n",
            "dunk is the character is the dunk of\n",
            "Duncan again I haven't really told this\n",
            "story yet so so you know we'll get to \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "sentences = list(doc.sents)\n",
        "\n",
        "print(\"Number of sentences:\", len(sentences))\n",
        "\n",
        "print(\"\\nFirst 5 sentences:\")\n",
        "for sent in sentences[:5]:\n",
        "    print(sent)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVbDfHlpjK7s",
        "outputId": "ac572a4b-7abe-4ce9-a3a5-ebfcda07918e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 2\n",
            "\n",
            "First 5 sentences:\n",
            "all right now this is a trial by combat\n",
            "if I am correct between sir Duncan the\n",
            "tall of the Kingsguard and Lord\n",
            "lyonel Baratheon and this is the the\n",
            "character in white sir Duncan is the\n",
            "dunk is the character is the dunk of\n",
            "Duncan again I haven't really told this\n",
            "story yet so so you know we'll get to it\n",
            "eventually in like the 7th or 8th Duncan\n",
            "egg story so he joins the Kingsguard\n",
            "newsflash\n",
            "well we kind of knew we kind of knew\n",
            "that that's that's in the books he's\n",
            "fighting lyonel Baratheon right that's\n",
            "the news flash right in his capacity as\n",
            "the leader of the Kingsguard I see well\n",
            "I'm not initially but eventually there's\n",
            "anything where you want to tell us about\n",
            "that no actually this was one of the\n",
            "hardest things about putting this book\n",
            "together what was the question of how\n",
            "much to tell and how much not to tell\n",
            "because the readers of course want to\n",
            "know everything and I knew some things\n",
            "and you know I'd shared some of them\n",
            "with my my editor and Grohl and someone\n",
            "with a Leo Linda but there are things\n",
            "that I wanted to reveal in later books\n",
            "in later novels or like in the case of\n",
            "that in later Duncan egg stories so it\n",
            "was it was like you know I suggested at\n",
            "one point like when we were dealing with\n",
            "one of the big mysteries of the that\n",
            "people want to know a lot about was\n",
            "summer home and if summer summer hall\n",
            "was a Targaryen secondary castle that\n",
            "was in the sort of the border where the\n",
            "Stormlands and the reach and the Dornish\n",
            "marches will come together and it was\n",
            "home castle two eggs father in the\n",
            "Duncan eight stories and to some other\n",
            "Targaryen princess during a certain\n",
            "period of time but it was destroyed that\n",
            "at a certain point there been references\n",
            "to the book something happened at\n",
            "summerholt something something dark and\n",
            "traumatic and what exactly happened and\n",
            "the readers will want to notice and I\n",
            "know what happened but I don't want to\n",
            "tell the readers yet because I want to\n",
            "reveal that in a later Duncan egg story\n",
            "but how do we get around that because\n",
            "the maester is writing the history and\n",
            "this is a very important event so I\n",
            "suggested that since we're doing this as\n",
            "the mock fact simile that perhaps mr.\n",
            "\n",
            "Yan Dale could write a detailed account\n",
            "and then accidentally knock over his\n",
            "inkwell and it would be a big blotch on\n",
            "that page when you when you got to that\n",
            "book that was my answer here and\n",
            "actually talked me out of that because\n",
            "she felt that that if we did that a lot\n",
            "of customers would be returning to the\n",
            "book something I got a defective copy\n",
            "there's a big blotch here I'm taking\n",
            "three hundred and fourteen could you\n",
            "give me a copy that has that in you're\n",
            "not gonna actually find out much about\n",
            "summerhall in this book sorry to tell\n",
            "you we didn't do it a blotch but we got\n",
            "around it another matter but that was\n",
            "unfortunately my reaction to a lot of\n",
            "this stuff at whoa wait a minute I don't\n",
            "want to reveal that I'm gonna use that\n",
            "in a later Duncan no no you can't tell\n",
            "them that that's a good detail no no no\n",
            "bleep that out there from the earlier in\n",
            "Lindon an ganged up why's that you have\n",
            "to tell them some of these things so I\n",
            "did and actually they made up you know\n",
            "they're there\n",
            "there's amazing amount of new material\n",
            "in this book and and stories that I made\n",
            "up just for the book and stories that I\n",
            "eventually was going to include the\n",
            "novel and they've still being the novels\n",
            "of the Duncan egg story but if you read\n",
            "this you already know somewhat of what\n",
            "has happened so there's there's lots of\n",
            "new stuff in here but I still fix\n",
            "feelings about telling things like that\n",
            "do what Sorbara thought and the laughing\n",
            "norm but I'll get to eventually\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [token.text.lower() for token in doc if token.is_alpha]\n",
        "\n",
        "print(\"Total words:\", len(words))\n",
        "print(\"Unique words:\", len(set(words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTGj5l7jaqT",
        "outputId": "d45f8cee-756d-4857-8e0c-a9b513fbe73e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: 697\n",
            "Unique words: 249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_freq = Counter(words)\n",
        "\n",
        "print(\"Top 10 most frequent words:\")\n",
        "for word, count in word_freq.most_common(10):\n",
        "    print(word, count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2enWRZEjgO0",
        "outputId": "a3ca3faf-3088-4941-93ec-a15874b46d89"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most frequent words:\n",
            "the 38\n",
            "that 33\n",
            "and 27\n",
            "of 22\n",
            "i 21\n",
            "to 20\n",
            "a 19\n",
            "in 17\n",
            "you 14\n",
            "was 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc2 = nlp2(text)\n",
        "\n",
        "print(\"Named Entities:\")\n",
        "for ent in doc2.ents:\n",
        "    print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5LwIi96j04L",
        "outputId": "22d2a388-accc-4c72-951d-0acae7bee595"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Named Entities:\n",
            "Duncan PERSON\n",
            "Kingsguard PERSON\n",
            "Baratheon ORG\n",
            "Duncan PERSON\n",
            "Duncan PERSON\n",
            "7th ORDINAL\n",
            "8th ORDINAL\n",
            "Duncan PERSON\n",
            "Kingsguard PERSON\n",
            "Baratheon ORG\n",
            "Grohl PERSON\n",
            "Linda PERSON\n",
            "Duncan PERSON\n",
            "one CARDINAL\n",
            "one CARDINAL\n",
            "summer DATE\n",
            "summer summer DATE\n",
            "Targaryen ORG\n",
            "Dornish NORP\n",
            "two CARDINAL\n",
            "Duncan PERSON\n",
            "eight CARDINAL\n",
            "Duncan PERSON\n",
            "Yan Dale PERSON\n",
            "three hundred and fourteen CARDINAL\n",
            "a minute TIME\n",
            "Duncan PERSON\n",
            "Lindon GPE\n",
            "Duncan PERSON\n",
            "Sorbara PERSON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.matcher import PhraseMatcher\n",
        "\n",
        "matcher = PhraseMatcher(nlp2.vocab, attr=\"LOWER\")\n",
        "\n",
        "phrases = [\"united states\", \"america\", \"country\"]\n",
        "\n",
        "patterns = [nlp2(p) for p in phrases]\n",
        "\n",
        "matcher.add(\"TECH_TERMS\", patterns)\n",
        "\n",
        "matches = matcher(doc2)\n",
        "\n",
        "print(\"Matches found:\")\n",
        "for match_id, start, end in matches:\n",
        "    print(doc2[start:end])\n",
        "    print(\"Sentence:\", doc2[start].sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f_LxqkYj8-q",
        "outputId": "433426c1-d39e-47ef-95d2-326cfd644236"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matches found:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Everything went well for the most part other than the relevant phrases in phrasemaster.\n",
        "# I realized the subject of the video I picked was not related to anything tech wise.\n",
        "# It is cool to see the versatility of these tools, it has endless applications."
      ],
      "metadata": {
        "id": "bivDRKAykMIL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}